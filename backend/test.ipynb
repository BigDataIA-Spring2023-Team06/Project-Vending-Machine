{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Notebook\n",
    "\n",
    "This is an example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from github import Github\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import re\n",
    "import shutil\n",
    "from github import Github\n",
    "# import nbformat\n",
    "# from nbformat.v4 import new_notebook, new_code_cell\n",
    "\n",
    "GITHUB_ACCESS_TOKEN = os.getenv(\"GITHUB_ACCESS_TOKEN\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# g = Github(\"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\")\n",
    "# user_git = g.get_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "004a269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_suggestions(tools):\n",
    "    query = f\"give me detailed suggestions of 5 data engineering projects using {tools}\"\n",
    "\n",
    "    response =  openai.ChatCompletion.create(\n",
    "            model = \"gpt-3.5-turbo\", \n",
    "            messages = [\n",
    "                {\"role\" : \"user\", \"content\" : query }\n",
    "            ],\n",
    "            temperature = 1.0\n",
    "        )\n",
    "    res1 = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    gpt_response = res1\n",
    "    # Convert res1 to a list where bullet numbers start\n",
    "    res1 = re.sub(r'(\\n\\d+\\.)', r'\\n\\n\\1', res1)\n",
    "    #Convert res1 to a list by splitting on bullet numbers\n",
    "    res1 = re.split(r'\\n\\d+\\.', res1)\n",
    "    #remove \\n from every element in the list\n",
    "    res1 = [i.replace('\\n', '') for i in res1]\n",
    "    #remove the first character from every element in the list if it is a number\n",
    "    res1 = [i[1:] if i[0].isdigit() else i for i in res1]\n",
    "    #Remove any . from the beginning of every element in the list\n",
    "    res1 = [i[1:] if i[0] == '.' else i for i in res1]\n",
    "    #Remove any empty elements from the list\n",
    "    res1 = [i for i in res1 if i != '']\n",
    "    return res1, gpt_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fb044b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = \"AWS,FastAPI,Streamlit,Airflow,Docker,Great Expectations,SQL,Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dc32f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 ,gpt_reponse= project_suggestions(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4458cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ETL Pipeline for Sales Data AnalysisObjective: Create an automated ETL pipeline using AWS, Airflow, Docker, SQL, and Python to extract, transform, and load sales data from various sources into a centralized data warehouse for analysis. Approach:- Use AWS S3 and AWS Lambda functions for data ingestion and storage.- Write Python scripts for data transformation and cleaning.- Use Airflow DAGs to schedule and orchestrate the ETL pipeline.- Utilize Docker containers to manage the dependencies and environment.- Use SQL to create tables and query data in the data warehouse. - Implement Great Expectations for data validation and quality checks. \n",
      "*******************\n",
      " Real-Time Dashboard for Sensor Data VisualizationObjective: Build a real-time data dashboard using AWS, FastAPI, Streamlit, and Python to visualize sensor data for monitoring and analysis. Approach:- Use AWS IoT and AWS Kinesis for the ingestion and storage of sensor data.- Build a FastAPI web server to retrieve the data and perform any necessary calculations or transformations.- Use Streamlit for building a web-based user interface that displays the data in real-time and allows for user interaction.- Enable Docker containers to deploy and manage the application on various platforms.- Utilize Python for data processing and transformation.- Implement Great Expectations for data validation and quality checks.\n",
      "*******************\n",
      " Data Pipeline for Healthcare Data ProcessingObjective: Create an automated data pipeline using AWS, Airflow, Docker, SQL, and Python to extract, transform, and load healthcare data from various sources into a centralized data warehouse for analysis. Approach:- Use AWS S3 and AWS Lambda functions for data ingestion and storage.- Write Python scripts for data transformation and cleaning.- Implement Airflow DAGs to schedule and orchestrate the ETL pipeline.- Utilize Docker containers to manage the dependencies and environment.- Use SQL to create tables and query data in the data warehouse.- Utilize Great Expectations for data validation and quality checks. \n",
      "*******************\n",
      " Data Pipeline for Social Media Sentiment AnalysisObjective: Build an automated pipeline using AWS, Airflow, Docker, SQL, and Python to extract, transform, and load social media data into a centralized data warehouse for sentiment analysis. Approach:- Use AWS S3 and AWS Lambda functions to ingest data from social media platforms.- Write Python scripts for data transformation and cleaning.- Implement Airflow DAGs to schedule and orchestrate the ETL pipeline.- Utilize Docker containers for managing dependencies and environment.- Utilize SQL to create tables and query data in the data warehouse.- Utilize Python libraries for sentiment analysis and machine learning.- Implement Great Expectations for data validation and quality checks.\n",
      "*******************\n",
      " Data Pipeline for Log Analysis and VisualizationObjective: Build an automated data pipeline using AWS, Airflow, Docker, SQL, Streamlit, and Python to extract, transform, and load log data from various sources into a centralized data warehouse for analysis and visualization. Approach:- Use AWS S3 and AWS Lambda functions for data ingestion and storage.- Write Python scripts for data transformation and cleaning.- Implement Airflow DAGs to schedule and orchestrate the ETL pipeline.- Utilize Docker containers for managing dependencies and environment.- Use SQL to create tables and query data in the data warehouse.- Implement Streamlit for building a web-based user interface that displays the log data and allows for user interaction.- Utilize Great Expectations for data validation and quality checks.\n",
      "*******************\n"
     ]
    }
   ],
   "source": [
    "for i in res1:\n",
    "    print(i)\n",
    "    print(\"*******************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9f2561f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Real-time Data Streaming and Processing Pipeline:\n",
      "This project will stream real-time data from different sources and process it to provide insights. You can use Amazon Kinesis for data streaming, AWS Lambda for processing, and Amazon Redshift for storing and analyzing data. The pipeline can be created using FastAPI and Python. Visualizations can be created using Streamlit.\n",
      "\n",
      "2. Serverless ETL Pipeline:\n",
      "Building a serverless ETL pipeline using AWS Lambda and Amazon S3. Data can be extracted from different sources, transformed to fit the desired structure, and loaded to the destination. Python can be used for coding the ETL jobs while SQL can be used to create the tables and manipulate data. Streamlit can be used for data analysis and visualization.\n",
      "\n",
      "3. Data Lake with Amazon S3:\n",
      "Building a data lake on Amazon S3 for storing and analyzing large datasets. FastAPI can be used to define endpoints for accessing the data. AWS Glue can be used for data transformation and cleaning. SQL can be used for performing queries and aggregating data. Streamlit can be used for data visualization using custom charts and graphs.\n",
      "\n",
      "4. Chatbot Analytics Dashboard:\n",
      "Building a dashboard for analyzing chatbot interactions using FastAPI and Streamlit. The data can be extracted from AWS Lex or Amazon Connect. Data can be cleaned and transformed using Python and SQL. Insights can be drawn using Streamlit custom charts and graphs. The dashboard can be made responsive with the help of FastAPI.\n",
      "\n",
      "5. Automated Data Processing and Visualization with Amazon Comprehend:\n",
      "Create an automated pipeline for processing data using Amazon Comprehend to extract insights. AWS Lambda can be used for data processing, Amazon S3 for data storage, and Amazon QuickSight for data visualization. FastAPI can be used to define endpoints to access the processed data. Streamlit can be used to create custom visualizations and dashboards. Python can be used for coding the pipeline.\n"
     ]
    }
   ],
   "source": [
    "print(gpt_reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1553d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Data Ingestion and Processing Pipeline: - AWS Services used: AWS S3, AWS Glue, AWS Athena, AWS Lambda- FastAPI as interface to upload data to AWS S3 bucket- AWS Glue to extract, transform, and load data from S3 bucket to AWS Athena- Streamlit for visualizing the processed data with graphs and statistical metrics', ' Real-time Sentiment Analysis Dashboard: - AWS Services used: Amazon Kinesis, AWS Comprehend, AWS S3, Amazon DynamoDB- FastAPI as endpoint to collect user feedback in real-time- Amazon Kinesis for data streaming, AWS Comprehend for sentiment analysis- AWS S3 for data storage and DynamoDB for metadata management- Streamlit for creating a dynamic dashboard that visualizes the processed data on a near real-time basis.', ' Web Scraper and Analyzer:- AWS Services used: AWS Lambda, AWS S3, AWS Glue, AWS Athena- FastAPI to accept user input URL parameters to collect and process specific data from a webpage- AWS Lambda function to execute the scraper code and using AWS S3 to store the collected data- AWS Glue to extract selected data and transform to .csv format for analytical purposes- AWS Athena as a datastore for running SQL queries to perform data analyses and generate statistics- Streamlit to create dashboards that visualize the results of analyses.', ' Data Warehousing:- AWS Services used: Redshift, AWS Lambda, AWS S3, AWS Glue, AWS Athena- FastAPI to accept user input and store data in AWS S3 bucket- AWS Lambda function to extract, transform, and load data from AWS S3 to Redshift through AWS Glue- AWS Athena as a query tool for users to interact with the data stored in Redshift- Streamlit to create a dashboard that visualizes key metrics stored in the Redshift data warehouse and enables data exploration.', ' Machine Learning Model Deployment:- AWS Services used: AWS Sagemaker, AWS Lambda, AWS S3- FastAPI to accept user input and saved data in AWS S3 bucket- AWS Lambda function to deploy a previously built machine learning model stored in AWS Sagemaker- AWS S3 for storing model training data and final model artifacts- Streamlit for creating a dashboard to interact with the deployed model and display predictions from the model.']\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7eab12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_structure_code(selected_project: str,full_response: str,tools: str):\n",
    "    #Convert res1 list to a string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages = [{\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"give me suggestions of data engineering projects using {tools}\"},\n",
    "    {\"role\": \"assistant\", \"content\" : full_response},\n",
    "    {\"role\": \"user\", \"content\" : f\"give me python code to create the file structure and empty files in each folder for this project and I should be able to run the code without any changes:{selected_project}\"}]\n",
    "    )\n",
    "\n",
    "    res2 = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    pattern = r\"```(.+?)```\"\n",
    "    code = re.search(pattern, res2, re.DOTALL).group(1)\n",
    "    if \"python\" in code:\n",
    "        code = code.replace(\"python\", \" \")\n",
    "\n",
    "    return code\n",
    "\n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "43d60c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_project= res1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c34d4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = get_project_structure_code(selected_project,gpt_reponse,tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "133d9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import os\n",
      "\n",
      "# Create the main project folder\n",
      "project_folder = \"Data Pipeline for Social Media Sentiment Analysis\"\n",
      "if not os.path.exists(project_folder):\n",
      "    os.mkdir(project_folder)\n",
      "\n",
      "# Create subfolders for each component of the project\n",
      "aws_folder = os.path.join(project_folder, \"AWS\")\n",
      "if not os.path.exists(aws_folder):\n",
      "    os.mkdir(aws_folder)\n",
      "\n",
      " _folder = os.path.join(project_folder, \"Python\")\n",
      "if not os.path.exists( _folder):\n",
      "    os.mkdir( _folder)\n",
      "\n",
      "airflow_folder = os.path.join(project_folder, \"Airflow\")\n",
      "if not os.path.exists(airflow_folder):\n",
      "    os.mkdir(airflow_folder)\n",
      "\n",
      "docker_folder = os.path.join(project_folder, \"Docker\")\n",
      "if not os.path.exists(docker_folder):\n",
      "    os.mkdir(docker_folder)\n",
      "\n",
      "sql_folder = os.path.join(project_folder, \"SQL\")\n",
      "if not os.path.exists(sql_folder):\n",
      "    os.mkdir(sql_folder)\n",
      "\n",
      "# Create empty files for each component\n",
      "aws_file = os.path.join(aws_folder, \"aws.py\")\n",
      "if not os.path.exists(aws_file):\n",
      "    open(aws_file, 'w').close()\n",
      "\n",
      " _file = os.path.join( _folder, \"transform.py\")\n",
      "if not os.path.exists( _file):\n",
      "    open( _file, 'w').close()\n",
      "\n",
      "airflow_file = os.path.join(airflow_folder, \"dags.py\")\n",
      "if not os.path.exists(airflow_file):\n",
      "    open(airflow_file, 'w').close()\n",
      "\n",
      "docker_file = os.path.join(docker_folder, \"Dockerfile\")\n",
      "if not os.path.exists(docker_file):\n",
      "    open(docker_file, 'w').close()\n",
      "\n",
      "sql_file = os.path.join(sql_folder, \"queries.sql\")\n",
      "if not os.path.exists(sql_file):\n",
      "    open(sql_file, 'w').close()\n",
      "\n",
      "# Create a file for Great Expectations\n",
      "great_expectations_file = os.path.join(project_folder, \"great_expectations.yml\")\n",
      "if not os.path.exists(great_expectations_file):\n",
      "    open(great_expectations_file, 'w').close()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fd2f3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import uuid\n",
    "from github import Github, GithubException\n",
    "\n",
    "def make_project(code,gpt_reponse,selected_project,tools):\n",
    "    # Create a temporary directory to store the file structure\n",
    "    temp_dir = f\"temp_{uuid.uuid4().hex}\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Write the code to a Python file in the temporary directory\n",
    "        with open(f\"{temp_dir}/file_structure.py\", \"w\") as f:\n",
    "            f.write(code)\n",
    "\n",
    "        # Run the Python file to create the file structure in the temporary directory\n",
    "        os.chdir(temp_dir)\n",
    "        os.system(\"python file_structure.py\")\n",
    "\n",
    "\n",
    "        # Return a dictionary mapping directories to files\n",
    "        output_dict = {}\n",
    "        for root, dirs, files in os.walk(\".\"):\n",
    "            if root != \".\":\n",
    "                output_dict[root[2:]] = files\n",
    "        print(output_dict)\n",
    "        # Go through each value in the dictionary and send requests to the OpenAI API to generate code for each file and add into the file\n",
    "        for key, value in output_dict.items():\n",
    "            for file in value:\n",
    "                if value != []:\n",
    "                    code_base = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\", \n",
    "                    messages = [{\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "                {\"role\": \"user\", \"content\" : f\"give me suggestions of data engineering projects using {tools}\"},\n",
    "                {\"role\": \"assistant\", \"content\" : gpt_reponse},\n",
    "                {\"role\": \"user\", \"content\" : f\"give me python code to create the file structure and empty files in each folder for this project:{selected_project}\"},\n",
    "                {\"role\": \"assistant\", \"content\" : code},\n",
    "                {\"role\": \"user\", \"content\" : f\"give me python code for each file: {file} in the folder: {key}\"}]\n",
    "                )\n",
    "                    generated_code = code_base[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "                    pattern = r\"```(.+?)```\"\n",
    "                    matches = re.findall(pattern, generated_code, re.DOTALL)\n",
    "                    if matches:\n",
    "                        generated_code = matches[0]\n",
    "                    else:\n",
    "                        # Handle the case where no matches are found\n",
    "                        generated_code = \"\"\n",
    "\n",
    "                    # Write the code to the file\n",
    "                    with open(f\"{key}/{file}\", \"w\") as f:\n",
    "                        f.write(generated_code)\n",
    "\n",
    "        # Create a GitHub repository and upload the file structure\n",
    "        g = Github(GITHUB_ACCESS_TOKEN)\n",
    "        user = g.get_user()\n",
    "        repo_name = f\"Project-{int(time.time())}\"\n",
    "        repo = user.create_repo(repo_name)\n",
    "        for root, dirs, files in os.walk(\".\"):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    content = f.read()\n",
    "                try:\n",
    "                    repo.create_file(file_path[2:], f\"Add {file}\", content, branch=\"main\")\n",
    "                except GithubException as e:\n",
    "                    print(f\"Error uploading file {file_path}: {e}\")\n",
    "\n",
    "        # remove file_structure.py\n",
    "        os.remove(\"file_structure.py\")\n",
    "\n",
    "        # Return the GitHub repository URL\n",
    "        return repo.html_url\n",
    "\n",
    "    finally:\n",
    "        # Clean up the temporary directory\n",
    "        os.chdir(\"..\")\n",
    "        shutil.rmtree(temp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75903f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "deb65bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohan/Desktop/Project-Vending-Machine-/backend\n"
     ]
    }
   ],
   "source": [
    "# #Check the current working directory\n",
    "print(os.getcwd())\n",
    "# shutil.rmtree(\"temp\")\n",
    "# #Set the current working directory to the backend directory\n",
    "os.chdir(\"/Users/mohan/Desktop/Project-Vending-Machine-/backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f231478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/mohan/Desktop/Project-Vending-Machine-/backend/temp_d3821cf7f87741b09e6316bf3af6f6ef/file_structure.py\", line 14\n",
      "    _folder = os.path.join(project_folder, \"Python\")\n",
      "                                                    ^\n",
      "IndentationError: unindent does not match any outer indentation level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "res4 = generate_file_dictionary(res3,gpt_reponse,selected_project,tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "56e9e9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/project-vending/Project-1682462877\n"
     ]
    }
   ],
   "source": [
    "print(res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d9b0bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through each value in the dictionary and send requests to the OpenAI API to generate code for each file\n",
    "def code_generate(file_structure_dict,gpt_reponse,selected_project,code):\n",
    "    for key, value in file_structure_dict.items():\n",
    "    code_base = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages = [{\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "    {\"role\": \"user\", \"content\" : \"give me suggestions of data engineering projects using FastAPI, Streamlit and AWS\"},\n",
    "    {\"role\": \"assistant\", \"content\" : gpt_reponse},\n",
    "    {\"role\": \"user\", \"content\" : f\"give me python code to create the file structure and empty files in each folder for this project:{selected_project}\"},\n",
    "    {\"role\": \"assistant\", \"content\" : code},\n",
    "    {\"role\": \"user\", \"content\" : f\"give me python code for each file:{file_structure_dict}\"},]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aaa7cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_base1,code_base2 = code_generate(res4,gpt_reponse,selected_project,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f454e32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly, here are sample codes for each file in the project structure you provided using Python:\n",
      "\n",
      "1. `aws_athena_queries.sql`:\n",
      "\n",
      "This file contains the SQL queries that will be used to perform data analyses on the stored data in AWS Athena. Below is a sample code:\n",
      "\n",
      "```\n",
      "-- create Athena table\n",
      "CREATE EXTERNAL TABLE IF NOT EXISTS my_table (\n",
      "    col_1 STRING,\n",
      "    col_2 STRING,\n",
      "    col_3 INT\n",
      ") \n",
      "ROW FORMAT DELIMITED \n",
      "FIELDS TERMINATED BY ',' \n",
      "LOCATION 's3://my-bucket/my-data-folder/';\n",
      "\n",
      "-- sample query to get count of distinct values in a column\n",
      "SELECT col_1, COUNT(DISTINCT col_2) AS distinct_count\n",
      "FROM my_table\n",
      "GROUP BY col_1;\n",
      "```\n",
      "\n",
      "2. `aws_glue_script.py`:\n",
      "\n",
      "This file contains the code that will be executed in the AWS Glue ETL job to extract and transform data from AWS S3 into CSV format. Below is a sample code:\n",
      "\n",
      "```\n",
      "import sys\n",
      "from awsglue.transforms import *\n",
      "from awsglue.utils import getResolvedOptions\n",
      "from pyspark.context import SparkContext\n",
      "from pyspark.sql.functions import col\n",
      "from awsglue.context import GlueContext\n",
      "from awsglue.dynamicframe import DynamicFrame\n",
      "\n",
      "\n",
      "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
      "sc = SparkContext()\n",
      "glueContext = GlueContext(sc)\n",
      "spark = glueContext.spark_session\n",
      "\n",
      "# Read data from S3 bucket\n",
      "input_df = spark.read.csv(\"s3://my-bucket/raw-data-folder/\", header=True, inferSchema=True)\n",
      "\n",
      "# Transformation operations\n",
      "transformed_df = input_df.filter(col(\"col_1\") == \"desired_value\")\n",
      "transformed_dynamic_frame = DynamicFrame.fromDF(transformed_df, glueContext, \"transformed_df\")\n",
      "\n",
      "# Write data to S3 bucket in CSV format\n",
      "glueContext.write_dynamic_frame.from_options(\n",
      "    frame = transformed_dynamic_frame,\n",
      "    connection_type = \"s3\",\n",
      "    connection_options = {\"path\": \"s3://my-bucket/csv-folder/\"},\n",
      "    format = \"csv\"\n",
      ")\n",
      "```\n",
      "\n",
      "3. `scraper_lambda.py`:\n",
      "\n",
      "This file contains the code for an AWS Lambda function that will execute the scraper code to collect data from a webpage and store it in AWS S3. Below is a sample code:\n",
      "\n",
      "```\n",
      "import requests\n",
      "import boto3\n",
      "\n",
      "def lambda_handler(event, context):\n",
      "    # Get URL from user input\n",
      "    url = event[\"url\"]\n",
      "    \n",
      "    # Make request to webpage\n",
      "    response = requests.get(url)\n",
      "    \n",
      "    # Store data in S3\n",
      "    s3 = boto3.resource(\"s3\")\n",
      "    s3.Object(\"my-bucket\", \"raw-data-folder/file.txt\").put(Body=response.content)\n",
      "```\n",
      "\n",
      "4. `raw_data.csv`:\n",
      "\n",
      "This file contains sample raw data collected from a webpage. Below is a sample data:\n",
      "\n",
      "```\n",
      "col_1,col_2,col_3\n",
      "value_1,value_2,1\n",
      "value_2,value_3,2\n",
      "value_3,value_4,3\n",
      ".\n",
      ".\n",
      ".\n",
      "```\n",
      "\n",
      "5. `app.py`:\n",
      "\n",
      "This file contains the code for a FastAPI app that accepts user input URL parameters to collect and process specific data from a webpage. Below is a sample code:\n",
      "\n",
      "```\n",
      "from fastapi import FastAPI\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "@app.get(\"/\")\n",
      "async def read_root():\n",
      "    return {\"message\": \"Welcome to the WebScraperAnalyzer app!\"}\n",
      "\n",
      "@app.get(\"/scrape/\")\n",
      "async def scrape_website(url: str):\n",
      "    # execute scraper code\n",
      "\n",
      "@app.post(\"/transform/\")\n",
      "async def transform_data(column: str):\n",
      "    # execute AWS Glue script to transform data\n",
      "\n",
      "@app.get(\"/analyze/\")\n",
      "async def analyze_data(query: str):\n",
      "    # execute AWS Athena query to analyze data\n",
      "\n",
      "@app.get(\"/dashboard/\")\n",
      "async def streamlit_dashboard():\n",
      "    # launch Streamlit dashboard\n",
      "```\n",
      "\n",
      "6. `streamlit_app.py`:\n",
      "\n",
      "This file contains the code for a Streamlit app that visualizes the results of analyses performed with AWS Athena. Below is a sample code:\n",
      "\n",
      "```\n",
      "import streamlit as st\n",
      "import pandas as pd\n",
      "import boto3\n",
      "import pandasathena as pdath\n",
      "\n",
      "# Initialize Athena connection\n",
      "athena_conn = boto3.client(\"athena\")\n",
      "\n",
      "# Sample query to get data\n",
      "query = \"SELECT * FROM my_table;\"\n",
      "\n",
      "# Get query results\n",
      "query_results = pdath.read_sql(query, cursor=athena_conn)\n",
      "\n",
      "# Display data in Streamlit app\n",
      "st.dataframe(query_results)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(code_base1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d61a57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's the remaining code for each file:\n",
      "\n",
      "1. `app.py` in `./WebScraperAnalyzer/src`:\n",
      "\n",
      "```\n",
      "from fastapi import FastAPI\n",
      "from fastapi.middleware.cors import CORSMiddleware\n",
      "from scraper_lambda import scrape_and_store\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "# Set up CORS for cross-origin requests\n",
      "origins = [\n",
      "    \"http://localhost\",\n",
      "    \"http://localhost:8000\",\n",
      "    \"http://localhost:3000\",\n",
      "]\n",
      "app.add_middleware(\n",
      "    CORSMiddleware,\n",
      "    allow_origins=origins,\n",
      "    allow_credentials=True,\n",
      "    allow_methods=[\"*\"],\n",
      "    allow_headers=[\"*\"],\n",
      ")\n",
      "\n",
      "@app.post(\"/\")\n",
      "async def scrape_and_process(url: str):\n",
      "    # Call Lambda function to scrape data from URL and store in S3\n",
      "    scrape_and_store(url)\n",
      "    \n",
      "    return {\"status\": \"success\"}\n",
      "```\n",
      "\n",
      "2. `raw_data.csv` in `./WebScraperAnalyzer/data`:\n",
      "\n",
      "```\n",
      "(This file is intentionally left blank - it will be populated with data from the scraper code later)\n",
      "```\n",
      "\n",
      "3. `scraper_lambda.py` in `./WebScraperAnalyzer/aws_lambda`:\n",
      "\n",
      "```\n",
      "import boto3\n",
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "import csv\n",
      "from io import StringIO\n",
      "\n",
      "# Configuration\n",
      "S3_BUCKET = 'your-s3-bucket-name'\n",
      "S3_KEY = 'your-s3-object-key'\n",
      "\n",
      "def scrape_and_store(url):\n",
      "    # Get page data\n",
      "    page_data = requests.get(url).content\n",
      "    soup = BeautifulSoup(page_data, 'html.parser')\n",
      "    \n",
      "    # TODO: Implement code to extract relevant data from page\n",
      "    \n",
      "    # Write data to S3\n",
      "    s3 = boto3.resource('s3')\n",
      "    csvio = StringIO()\n",
      "    writer = csv.writer(csvio)\n",
      "    \n",
      "    # TODO: Generate CSV with relevant data\n",
      "    \n",
      "    s3.Bucket(S3_BUCKET).put_object(Key=S3_KEY, Body=csvio.getvalue())\n",
      "```\n",
      "\n",
      "4. `aws_glue_script.py` in `./WebScraperAnalyzer/aws_glue`:\n",
      "\n",
      "```\n",
      "import sys\n",
      "from awsglue.transforms import *\n",
      "from awsglue.utils import getResolvedOptions\n",
      "from pyspark.context import SparkContext\n",
      "from pyspark.sql.session import SparkSession\n",
      "\n",
      "# Configuration\n",
      "S3_BUCKET = 'your-s3-bucket-name'\n",
      "S3_KEY = 'your-s3-object-key'\n",
      "\n",
      "# Get job arguments\n",
      "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
      "\n",
      "sc = SparkContext()\n",
      "glueContext = GlueContext(sc)\n",
      "spark = glueContext.spark_session\n",
      "\n",
      "# Load data from S3 and convert to DataFrame\n",
      "df = spark.read.option(\"header\", \"true\").csv(f\"s3://{S3_BUCKET}/{S3_KEY}\")\n",
      "\n",
      "# TODO: Implement code to clean and transform data as necessary\n",
      "\n",
      "# Write transformed data to S3 in CSV format\n",
      "output_dir = \"s3://your-s3-bucket/output_data/\"\n",
      "df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_dir)\n",
      "```\n",
      "\n",
      "5. `aws_athena_queries.sql` in `./WebScraperAnalyzer/aws_athena`:\n",
      "\n",
      "```\n",
      "-- Configuration\n",
      "DATABASE_NAME = \"web_scraper_analyzer\"\n",
      "\n",
      "-- Create the table to hold the raw data\n",
      "CREATE EXTERNAL TABLE raw_data (\n",
      "    -- TODO: Define columns based on structure of scraped data\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
      "STORED AS TEXTFILE\n",
      "LOCATION 's3://your-s3-bucket/output_data/';\n",
      "\n",
      "-- Create a cleaned version of the data\n",
      "CREATE OR REPLACE VIEW cleaned_data AS (\n",
      "    -- TODO: Implement code to clean and transform data as necessary\n",
      ");\n",
      "\n",
      "-- Example queries\n",
      "SELECT COUNT(*) as total_records FROM cleaned_data;\n",
      "SELECT column1, column2, COUNT(*) as count FROM cleaned_data GROUP BY column1, column2 ORDER BY count DESC;\n",
      "```\n",
      "\n",
      "6. `streamlit_app.py` in `./WebScraperAnalyzer/streamlit_dashboard`:\n",
      "\n",
      "```\n",
      "import streamlit as st\n",
      "import pandas as pd\n",
      "import boto3\n",
      "from io import StringIO\n",
      "\n",
      "# Set up connection to Athena\n",
      "ATHENA_OUTPUT_BUCKET = \"athena-query-results-bucket\"\n",
      "DATABASE = \"web_scraper_analyzer\"\n",
      "\n",
      "def run_query(query):\n",
      "    client = boto3.client(\"athena\")\n",
      "    response = client.start_query_execution(\n",
      "        QueryString=query,\n",
      "        QueryExecutionContext={\n",
      "            \"Database\": DATABASE\n",
      "        },\n",
      "        ResultConfiguration={\n",
      "            \"OutputLocation\": f\"s3://{ATHENA_OUTPUT_BUCKET}\"\n",
      "        }\n",
      "    )\n",
      "    execution_id = response[\"QueryExecutionId\"]\n",
      "    state = \"RUNNING\"\n",
      "\n",
      "    while state in [\"RUNNING\", \"QUEUED\"]:\n",
      "        response = client.get_query_execution(QueryExecutionId=execution_id)\n",
      "        state = response[\"QueryExecution\"][\"Status\"][\"State\"]\n",
      "\n",
      "    if state == \"FAILED\":\n",
      "        error = response[\"QueryExecution\"][\"Status\"][\"StateChangeReason\"]\n",
      "        raise ValueError(f\"Athena query failed: {error}\")\n",
      "\n",
      "    s3_client = boto3.client(\"s3\")\n",
      "    results_key = response[\"QueryExecution\"][\"ResultConfiguration\"][\"OutputLocation\"].replace(f\"s3://{ATHENA_OUTPUT_BUCKET}/\", \"\")\n",
      "    results = s3_client.get_object(Bucket=ATHENA_OUTPUT_BUCKET, Key=results_key)[\"Body\"].read().decode(\"utf-8\")\n",
      "\n",
      "    return pd.read_csv(StringIO(results))\n",
      "\n",
      "# Define Streamlit app\n",
      "def app():\n",
      "    st.title(\"Web Scraper Analyzer Dashboard\")\n",
      "    \n",
      "    # Collect URL input from user via FastAPI\n",
      "    url_input = st.text_input(\"Enter a URL to scrape:\")\n",
      "    if st.button(\"Scrape and process\"):\n",
      "        response = requests.post(\"http://localhost:8000/\", json={\"url\": url_input})\n",
      "        if response.status_code == 200:\n",
      "            st.success(\"Data successfully scraped and processed!\")\n",
      "        else:\n",
      "            st.error(\"Failed to scrape and process data.\")\n",
      "    \n",
      "    # Load data from Athena\n",
      "    query = \"SELECT * FROM cleaned_data\"\n",
      "    df = run_query(query)\n",
      "    \n",
      "    # Display data in Streamlit\n",
      "    st.write(df)\n",
      "```\n",
      "\n",
      "To run this project, you'll need to:\n",
      "\n",
      "1. Create an S3 bucket and update the `S3_BUCKET` and `S3_KEY` variables in `scraper_lambda.py` and `aws_glue_script.py` to reflect your bucket and key names.\n",
      "2. Create a Glue job with the Python script defined in `aws_glue_script.py` and ensure that the Glue job has permissions to read from and write to your S3 bucket.\n",
      "3. Create an Athena database and table (using `aws_athena_queries.sql`) to reference the output data from your Glue job.\n",
      "4. Update the `ATHENA_OUTPUT_BUCKET` and `DATABASE` variables in `streamlit_app.py` to reflect your Athena output bucket and database names.\n",
      "5. Run the FastAPI app defined in `app.py` with `uvicorn src.app:app --reload`.\n",
      "6. Run the Streamlit app defined in `streamlit_app.py` with `streamlit run streamlit_dashboard/streamlit_app.py`.\n",
      "\n",
      "Note that you will need to configure credentials for connecting to AWS services and potentially install additional libraries to run this code.\n"
     ]
    }
   ],
   "source": [
    "print(code_base2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f2570ee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "code_generate() missing 1 required positional argument: 'code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m code_base \u001b[39m=\u001b[39m code_generate(res4,gpt_reponse,selected_project)\n",
      "\u001b[0;31mTypeError\u001b[0m: code_generate() missing 1 required positional argument: 'code'"
     ]
    }
   ],
   "source": [
    "code_base = code_generate(res4,gpt_reponse,selected_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a3c4dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code for each file in the file structure tree \u001b[01;34m.\u001b[0m\n",
      "└── \u001b[01;34mWebScraperAnalyzer\u001b[0m\n",
      "    ├── \u001b[01;34maws_athena\u001b[0m\n",
      "    │   └── \u001b[00maws_athena_queries.sql\u001b[0m\n",
      "    ├── \u001b[01;34maws_glue\u001b[0m\n",
      "    │   └── \u001b[00maws_glue_script.py\u001b[0m\n",
      "    ├── \u001b[01;34maws_lambda\u001b[0m\n",
      "    │   └── \u001b[00mscraper_lambda.py\u001b[0m\n",
      "    ├── \u001b[01;34mdata\u001b[0m\n",
      "    │   └── \u001b[00mraw_data.csv\u001b[0m\n",
      "    ├── \u001b[01;34msrc\u001b[0m\n",
      "    │   └── \u001b[00mapp.py\u001b[0m\n",
      "    └── \u001b[01;34mstreamlit_dashboard\u001b[0m\n",
      "        └── \u001b[00mstreamlit_app.py\u001b[0m\n",
      "\n",
      "8 directories, 6 files\n",
      " \n",
      "  \n",
      "Project description: Web Scraper and Analyzer\n",
      "\n",
      "This FastAPI-Based Web Scraper and Analyzer will accept HTTP request and scrape the input URL, search and extract the data of interest, store the data in AWS S3, using Athena as datastore and Glue service to transform the data format from .json to .csv. \n",
      "\n",
      "The data stored can then be analyzes, for example, some statistics can be performed.\n",
      "\n",
      "AWS Services used:\n",
      "FastAPI - API framework for Python\n",
      "AWS Lambda- for scraper code execution\n",
      "AWS S3 - storage\n",
      "AWS Glue - .json to .csv data transformation\n",
      "AWS Athena as a datastore for running SQL queries\n",
      "Streamlit - to create dashboards that visualize the results of analyses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "37a6a32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohan/Desktop/Project-Vending-Machine-/backend\n"
     ]
    }
   ],
   "source": [
    "#current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "b34d7099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Automatic Data Ingestion: Combine AWS Lambda and Amazon S3 to automatically ingest and transform data on a schedule. You can use FastAPI to provide a RESTful API to control the ingestion schedule and Streamlit to create the dashboards to display the status of the processing.\n"
     ]
    }
   ],
   "source": [
    "print(res1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "c10f98ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import os\n",
      "\n",
      "# File structure\n",
      "folders = ['data_lake', 'queries']\n",
      "\n",
      "# Create folders and files\n",
      "for folder in folders:\n",
      "    try:\n",
      "        os.makedirs(folder)\n",
      "        if folder == 'queries':\n",
      "            open(os.path.join(folder, 'query_1.sql'), 'a').close()\n",
      "            open(os.path.join(folder, 'query_2.sql'), 'a').close()\n",
      "        elif folder == 'data_lake':\n",
      "            open(os.path.join(folder, 'structured_data.csv'), 'a').close()\n",
      "            open(os.path.join(folder, 'unstructured_data.txt'), 'a').close()\n",
      "    except FileExistsError:\n",
      "        print(f\"{folder} already exists\")\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "059b74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a python code snippet that creates the necessary file structure and empty files for the Natural Language Processing for customer service project you mentioned:\n",
      "\n",
      "```python\n",
      "import os\n",
      "\n",
      "# Define the directories and filenames for the project\n",
      "directories = ['model', 'data', 'app']\n",
      "model_files = ['train.py', 'model.py', 'utilities.py', '__init__.py']\n",
      "data_files = ['data.txt', 'labels.txt', '__init__.py']\n",
      "app_files = ['main.py', '__init__.py']\n",
      "\n",
      "# Create the directories and files\n",
      "for directory in directories:\n",
      "    os.makedirs(directory, exist_ok=True)\n",
      "    if directory == 'model':\n",
      "        for file in model_files:\n",
      "            with open(os.path.join(directory, file), 'w') as f:\n",
      "                pass\n",
      "    elif directory == 'data':\n",
      "        for file in data_files:\n",
      "            with open(os.path.join(directory, file), 'w') as f:\n",
      "                pass\n",
      "    elif directory == 'app':\n",
      "        for file in app_files:\n",
      "            with open(os.path.join(directory, file), 'w') as f:\n",
      "                pass\n",
      "```\n",
      "\n",
      "This code snippet creates three directories: model, data, and app. It creates empty files in the model and data directories and creates two files in the app directory: `main.py` and `__init__.py`. Once you have run this code, you will have the basic file structure for your project.\n"
     ]
    }
   ],
   "source": [
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "fd971065",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"```(.+?)```\"\n",
    "code = re.search(pattern, res2, re.DOTALL).group(1)\n",
    "if \"python\" in code:\n",
    "    code = code.replace(\"python\", \" \")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "5645a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "import os\n",
      "\n",
      "# Define the root project directory\n",
      "root_dir = 'Real-time_tweet_sentiment_analysis'\n",
      "\n",
      "# Define the directory structure\n",
      "dir_structure = {\n",
      "    'backend': {\n",
      "        'app': {\n",
      "            '__init__.py': '',\n",
      "            'main.py': '',\n",
      "        },\n",
      "        'sentiment_analysis': {\n",
      "            '__init__.py': '',\n",
      "            'analyzer.py': '',\n",
      "        },\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'frontend': {\n",
      "        '__init__.py': '',\n",
      "        'app.py': '',\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'README.md': '',\n",
      "}\n",
      "\n",
      "def create_dirs_and_files(path, structure):\n",
      "    \"\"\"Recursively create directories and files for a given structure.\"\"\"\n",
      "    for name, item in structure.items():\n",
      "        item_path = os.path.join(path, name)\n",
      "        if isinstance(item, dict):\n",
      "            os.makedirs(item_path, exist_ok=True)\n",
      "            create_dirs_and_files(item_path, item)\n",
      "        elif isinstance(item, str):\n",
      "            with open(item_path, 'w') as f:\n",
      "                f.write(item)\n",
      "\n",
      "# Create the project directory\n",
      "os.makedirs(root_dir, exist_ok=True)\n",
      "\n",
      "# Create the file structure\n",
      "create_dirs_and_files(root_dir, dir_structure)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "b3fdfa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a temp directory to store the .py file\n",
    "os.makedirs(\"temp\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "4a0c15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the code in a python file in the temp directory\n",
    "with open(\"temp/file_structure.py\", \"w\") as f:\n",
    "    f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "3454dd79",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[455], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Set the current working directory to the temp directory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m os\u001b[39m.\u001b[39;49mchdir(\u001b[39m\"\u001b[39;49m\u001b[39mtemp\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m#Run the python file to create the file structure in the temp directory\u001b[39;00m\n\u001b[1;32m      4\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39m\"\u001b[39m\u001b[39mpython file_structure.py\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp'"
     ]
    }
   ],
   "source": [
    "#Set the current working directory to the temp directory\n",
    "os.chdir(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "e5f45478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the python file to create the file structure in the temp directory\n",
    "os.system(\"python file_structure.py\")\n",
    "#Delete the python file\n",
    "os.remove(\"file_structure.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "e01364cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the names of all folders and files in the temp directory to a dictionary with folders as keys and files as values\n",
    "output_dict = {}\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    if root != \".\":\n",
    "        output_dict[root[2:]] = files\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "afb76a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Real-time_tweet_sentiment_analysis': ['README.md'], 'Real-time_tweet_sentiment_analysis/frontend': ['requirements.txt', 'Dockerfile', '__init__.py', 'app.py'], 'Real-time_tweet_sentiment_analysis/backend': ['requirements.txt', 'Dockerfile'], 'Real-time_tweet_sentiment_analysis/backend/app': ['__init__.py', 'main.py'], 'Real-time_tweet_sentiment_analysis/backend/sentiment_analysis': ['analyzer.py', '__init__.py']}\n"
     ]
    }
   ],
   "source": [
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "4a283b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohan/Desktop/Project-Vending-Machine-/backend/temp\n"
     ]
    }
   ],
   "source": [
    "#Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "8448d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go back to the root directory\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "e50ef507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#Delete the temp directory\n",
    "shutil.rmtree(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6e113ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, Here's a sample Python code to create the file structure and empty files for the Real-time tweet sentiment analysis project:\n",
      "\n",
      "```python\n",
      "import os\n",
      "\n",
      "# Define the root project directory\n",
      "root_dir = 'Real-time_tweet_sentiment_analysis'\n",
      "\n",
      "# Define the directory structure\n",
      "dir_structure = {\n",
      "    'backend': {\n",
      "        'app': {\n",
      "            '__init__.py': '',\n",
      "            'main.py': '',\n",
      "        },\n",
      "        'sentiment_analysis': {\n",
      "            '__init__.py': '',\n",
      "            'analyzer.py': '',\n",
      "        },\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'frontend': {\n",
      "        '__init__.py': '',\n",
      "        'app.py': '',\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'README.md': '',\n",
      "}\n",
      "\n",
      "def create_dirs_and_files(path, structure):\n",
      "    \"\"\"Recursively create directories and files for a given structure.\"\"\"\n",
      "    for name, item in structure.items():\n",
      "        item_path = os.path.join(path, name)\n",
      "        if isinstance(item, dict):\n",
      "            os.makedirs(item_path, exist_ok=True)\n",
      "            create_dirs_and_files(item_path, item)\n",
      "        elif isinstance(item, str):\n",
      "            with open(item_path, 'w') as f:\n",
      "                f.write(item)\n",
      "\n",
      "# Create the project directory\n",
      "os.makedirs(root_dir, exist_ok=True)\n",
      "\n",
      "# Create the file structure\n",
      "create_dirs_and_files(root_dir, dir_structure)\n",
      "```\n",
      "This will create the following file structure:\n",
      "\n",
      "```\n",
      "Real-time_tweet_sentiment_analysis/\n",
      "├── backend/\n",
      "│   ├── app/\n",
      "│   │   ├── __init__.py\n",
      "│   │   └── main.py\n",
      "│   ├── sentiment_analysis/\n",
      "│   │   ├── __init__.py\n",
      "│   │   └── analyzer.py\n",
      "│   ├── requirements.txt\n",
      "│   └── Dockerfile\n",
      "├── frontend/\n",
      "│   ├── __init__.py\n",
      "│   ├── app.py\n",
      "│   ├── requirements.txt\n",
      "│   └── Dockerfile\n",
      "└── README.md\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(completion[\"choices\"][0][\"message\"][\"content\"])\n",
    "res2 = completion[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "841bd5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, Here's a sample Python code to create the file structure and empty files for the Real-time tweet sentiment analysis project:\n",
      "\n",
      "```python\n",
      "import os\n",
      "\n",
      "# Define the root project directory\n",
      "root_dir = 'Real-time_tweet_sentiment_analysis'\n",
      "\n",
      "# Define the directory structure\n",
      "dir_structure = {\n",
      "    'backend': {\n",
      "        'app': {\n",
      "            '__init__.py': '',\n",
      "            'main.py': '',\n",
      "        },\n",
      "        'sentiment_analysis': {\n",
      "            '__init__.py': '',\n",
      "            'analyzer.py': '',\n",
      "        },\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'frontend': {\n",
      "        '__init__.py': '',\n",
      "        'app.py': '',\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'README.md': '',\n",
      "}\n",
      "\n",
      "def create_dirs_and_files(path, structure):\n",
      "    \"\"\"Recursively create directories and files for a given structure.\"\"\"\n",
      "    for name, item in structure.items():\n",
      "        item_path = os.path.join(path, name)\n",
      "        if isinstance(item, dict):\n",
      "            os.makedirs(item_path, exist_ok=True)\n",
      "            create_dirs_and_files(item_path, item)\n",
      "        elif isinstance(item, str):\n",
      "            with open(item_path, 'w') as f:\n",
      "                f.write(item)\n",
      "\n",
      "# Create the project directory\n",
      "os.makedirs(root_dir, exist_ok=True)\n",
      "\n",
      "# Create the file structure\n",
      "create_dirs_and_files(root_dir, dir_structure)\n",
      "```\n",
      "This will create the following file structure:\n",
      "\n",
      "```\n",
      "Real-time_tweet_sentiment_analysis/\n",
      "├── backend/\n",
      "│   ├── app/\n",
      "│   │   ├── __init__.py\n",
      "│   │   └── main.py\n",
      "│   ├── sentiment_analysis/\n",
      "│   │   ├── __init__.py\n",
      "│   │   └── analyzer.py\n",
      "│   ├── requirements.txt\n",
      "│   └── Dockerfile\n",
      "├── frontend/\n",
      "│   ├── __init__.py\n",
      "│   ├── app.py\n",
      "│   ├── requirements.txt\n",
      "│   └── Dockerfile\n",
      "└── README.md\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "9cb714ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"```(.+?)```\"\n",
    "code = re.search(pattern, res2, re.DOTALL).group(1)\n",
    "if \"python\" in code:\n",
    "    code = code.replace(\"python\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8410c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "import os\n",
      "\n",
      "# Define the root project directory\n",
      "root_dir = 'Real-time_tweet_sentiment_analysis'\n",
      "\n",
      "# Define the directory structure\n",
      "dir_structure = {\n",
      "    'backend': {\n",
      "        'app': {\n",
      "            '__init__.py': '',\n",
      "            'main.py': '',\n",
      "        },\n",
      "        'sentiment_analysis': {\n",
      "            '__init__.py': '',\n",
      "            'analyzer.py': '',\n",
      "        },\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'frontend': {\n",
      "        '__init__.py': '',\n",
      "        'app.py': '',\n",
      "        'requirements.txt': '',\n",
      "        'Dockerfile': '',\n",
      "    },\n",
      "    'README.md': '',\n",
      "}\n",
      "\n",
      "def create_dirs_and_files(path, structure):\n",
      "    \"\"\"Recursively create directories and files for a given structure.\"\"\"\n",
      "    for name, item in structure.items():\n",
      "        item_path = os.path.join(path, name)\n",
      "        if isinstance(item, dict):\n",
      "            os.makedirs(item_path, exist_ok=True)\n",
      "            create_dirs_and_files(item_path, item)\n",
      "        elif isinstance(item, str):\n",
      "            with open(item_path, 'w') as f:\n",
      "                f.write(item)\n",
      "\n",
      "# Create the project directory\n",
      "os.makedirs(root_dir, exist_ok=True)\n",
      "\n",
      "# Create the file structure\n",
      "create_dirs_and_files(root_dir, dir_structure)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6a522e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"file_structure.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "\n",
    "#Run the file_structure.py file to create the file structure\n",
    "os.system(\"python file_structure.py\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fe96cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages = [{\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "{\"role\": \"user\", \"content\" : \"give me suggestions of data engineering projects using FastAPI, Streamlit and AWS\"},\n",
    "{\"role\": \"assistant\", \"content\" : res1},\n",
    "{\"role\": \"user\", \"content\" : f\"give me a starter file structures and files in each folder for this project:{project}\"}, \n",
    "{\"role\": \"assistant\", \"content\" : res2}, \n",
    "{\"role\": \"user\", \"content\" : f\"{x} generate code for these files according to the project:{project}\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3e6b7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_structure(res2):\n",
    "    pattern = r\"```(.+?)```\"\n",
    "    response = re.search(pattern, res2, re.DOTALL).group(1)\n",
    "    file_structure_dict = {}\n",
    "\n",
    "    split_response = response.split(\"\\n\")\n",
    "\n",
    "    current_dir = None\n",
    "    for line in split_response:\n",
    "        if line.startswith('├──'):\n",
    "            # Remove the '├──' from the line\n",
    "            line = line.replace('├──', '')\n",
    "            # Add the line as a key to the dictionary\n",
    "            file_structure_dict[line] = []\n",
    "            current_dir = line\n",
    "        elif line.startswith('└──'):\n",
    "            # Remove the '└──' from the line\n",
    "            line = line.replace('└──', '')\n",
    "            # Add the line to the list of the current directory\n",
    "            file_structure_dict[current_dir].append(line)\n",
    "        elif '│' in line:\n",
    "            # Remove the leading spaces and vertical bars from the line\n",
    "            line = line.lstrip(' │')\n",
    "            if \"├──\" in line:\n",
    "                line = line.replace('├──', '')\n",
    "            elif \"└──\" in line:\n",
    "                line = line.replace('└──', '')\n",
    "            # Add the line to the list of the current directory\n",
    "            file_structure_dict[current_dir].append(line)\n",
    "        elif '└──' in line:\n",
    "            # Remove the '└──' from the line\n",
    "            line = line.replace('└──', '')\n",
    "            # Add the line to the list of the current directory\n",
    "            file_structure_dict[line] = []\n",
    "            current_dir = line\n",
    "    \n",
    "    return file_structure_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b7dc2ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(parse_file_structure(res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "336d4d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's an example Python code for each file according to the specified project:\n",
      "\n",
      "```\n",
      "├── etl\n",
      "│   ├── __init__.py\n",
      "│   ├── data_extractor.py\n",
      "│   ├── data_transformer.py\n",
      "│   └── data_loader.py\n",
      "```\n",
      "\n",
      "- `__init__.py`: Empty file, ensures the `etl` module can be imported correctly.\n",
      "\n",
      "- `data_extractor.py`: This file contains functions to extract data from the Kinesis stream using the Boto3 SDK.\n",
      "\n",
      "```python\n",
      "import boto3\n",
      "\n",
      "kinesis = boto3.client('kinesis')\n",
      "\n",
      "def extract_data_from_kinesis():\n",
      "    response = kinesis.get_records(\n",
      "        StreamName='my-stream', # Replace with your stream name\n",
      "        Limit=100\n",
      "    )\n",
      "    return [record['Data'] for record in response['Records']]\n",
      "```\n",
      "\n",
      "- `data_transformer.py`: This file contains functions to transform the raw data extracted from the stream.\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def transform_data(data):\n",
      "    # Extract the required fields from the JSON data\n",
      "    transformed_data = []\n",
      "    for record in data:\n",
      "        record_dict = json.loads(record)\n",
      "        transformed_record = {\n",
      "            'field_1': record_dict['field_1'],\n",
      "            'field_2': record_dict['field_2'],\n",
      "            'field_3': record_dict['field_3']\n",
      "            # Add more fields as required\n",
      "        }\n",
      "        transformed_data.append(transformed_record)\n",
      "    return transformed_data\n",
      "```\n",
      "\n",
      "- `data_loader.py`: This file contains functions to load the transformed data into DynamoDB.\n",
      "\n",
      "```python\n",
      "import boto3\n",
      "\n",
      "dynamodb = boto3.resource('dynamodb')\n",
      "table = dynamodb.Table('my-table') # Replace with your table name\n",
      "\n",
      "def load_data_to_dynamoDB(data):\n",
      "    with table.batch_writer() as batch:\n",
      "        for item in data:\n",
      "            batch.put_item(\n",
      "                Item=item\n",
      "            )\n",
      "```\n",
      "\n",
      "Note: You'll need to import the necessary packages and replace the placeholder values with the actual values for `StreamName` and `Table`.\n"
     ]
    }
   ],
   "source": [
    "print(completion[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "250c720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = '''     ├── database/\n",
    "    │   ├── Redshift/\n",
    "    │   │   ├── create_tables.sql\n",
    "    │   │   └── delete_tables.sql\n",
    "    │   └── RDS/\n",
    "    │       ├── create_tables.sql\n",
    "    │       └── delete_tables.sql'''\n",
    "    \n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages = [{\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "{\"role\": \"user\", \"content\" : \"give me suggestions of data engineering projects using FastAPI, Streamlit and AWS\"},\n",
    "{\"role\": \"assistant\", \"content\" : res1},\n",
    "{\"role\": \"user\", \"content\" : f\"give me a starter file structures and files in each folder for this project:{project}\"}, \n",
    "{\"role\": \"assistant\", \"content\" : res2}, \n",
    "{\"role\": \"user\", \"content\" : f\"{z} generate code for these files according to the project:{project}\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bd3402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a possible code for the `create_tables.sql` and `delete_tables.sql` scripts for the Real-time streaming data pipeline project:\n",
      "\n",
      "`Redshift/create_tables.sql`\n",
      "\n",
      "```sql\n",
      "CREATE TABLE incoming_data (\n",
      "    id BIGINT IDENTITY(1,1) PRIMARY KEY,\n",
      "    data JSON,\n",
      "    created_at TIMESTAMP DEFAULT getdate()\n",
      ");\n",
      "\n",
      "-- Additional tables can be added as needed.\n",
      "```\n",
      "\n",
      "`Redshift/delete_tables.sql`\n",
      "\n",
      "```sql\n",
      "DROP TABLE IF EXISTS incoming_data;\n",
      "\n",
      "-- Additional tables can be dropped as needed.\n",
      "```\n",
      "\n",
      "`RDS/create_tables.sql`\n",
      "\n",
      "```sql\n",
      "CREATE TABLE incoming_data (\n",
      "    id BIGINT AUTO_INCREMENT PRIMARY KEY,\n",
      "    data JSON,\n",
      "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
      ");\n",
      "\n",
      "-- Additional tables can be added as needed.\n",
      "```\n",
      "\n",
      "`RDS/delete_tables.sql`\n",
      "\n",
      "```sql\n",
      "DROP TABLE IF EXISTS incoming_data;\n",
      "\n",
      "-- Additional tables can be dropped as needed.\n",
      "```\n",
      "\n",
      "Note that the specific schema and fields for the database tables depend on the specific requirements of the project and can be adjusted as needed.\n"
     ]
    }
   ],
   "source": [
    "print(completion[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed74616",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = '''    ├── lambda_functions/\n",
    "    │   ├── __init__.py\n",
    "    │   ├── data_transformer_lambda.py\n",
    "    │   └── data_loader_lambda.py'''\n",
    "    \n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages = [{\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "{\"role\": \"user\", \"content\" : \"give me suggestions of data engineering projects using FastAPI, Streamlit and AWS\"},\n",
    "{\"role\": \"assistant\", \"content\" : res1},\n",
    "{\"role\": \"user\", \"content\" : f\"give me a starter file structures and files in each folder for this project:{project}\"}, \n",
    "{\"role\": \"assistant\", \"content\" : res2}, \n",
    "{\"role\": \"user\", \"content\" : f\"{y} generate code for these files according to the project:{project}\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ed283e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model: `code-davinci-002` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m top_p \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Generate code with the OpenAI API\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     10\u001b[0m   engine\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     11\u001b[0m   prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     12\u001b[0m   max_tokens\u001b[39m=\u001b[39;49mmax_tokens,\n\u001b[1;32m     13\u001b[0m   temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m     14\u001b[0m   top_p\u001b[39m=\u001b[39;49mtop_p,\n\u001b[1;32m     15\u001b[0m   n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m   stop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     17\u001b[0m   frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m   presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[39m# Extract the generated code from the API response\u001b[39;00m\n\u001b[1;32m     22\u001b[0m generated_code \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Desktop/Project-Vending-Machine-/venv/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Desktop/Project-Vending-Machine-/venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Desktop/Project-Vending-Machine-/venv/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Desktop/Project-Vending-Machine-/venv/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Project-Vending-Machine-/venv/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The model: `code-davinci-002` does not exist"
     ]
    }
   ],
   "source": [
    "# Define the parameters for the code generation\n",
    "prompt = \"Generate code to sort an array of integers in ascending order.\"\n",
    "model = \"code-davinci-002\"\n",
    "temperature = 0.7\n",
    "max_tokens = 100\n",
    "top_p = 1.0\n",
    "\n",
    "# Generate code with the OpenAI API\n",
    "response = openai.Completion.create(\n",
    "  engine=model,\n",
    "  prompt=prompt,\n",
    "  max_tokens=max_tokens,\n",
    "  temperature=temperature,\n",
    "  top_p=top_p,\n",
    "  n=1,\n",
    "  stop=None,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "# Extract the generated code from the API response\n",
    "generated_code = response.choices[0].text.strip()\n",
    "\n",
    "# Print the generated code\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6bb8ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x10a4039c0> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-edit-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-code-search-code\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-babbage-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-davinci-edit-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-003\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-internal\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-code-search-text\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-similarity\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"gpt-3.5-turbo\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-babbage-text-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-curie-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"whisper-1\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-internal\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-babbage-code-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-ada-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-embedding-ada-002\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-internal\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-ada-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"gpt-3.5-turbo-0301\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-instruct-beta\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-code-search-code\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-similarity\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-ada-text-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-ada-query-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-search-document\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-code-search-text\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-ada-doc-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-instruct-beta\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-curie-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-ada-code-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-search-query\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-davinci-query-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-search-query\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-search-query\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-search-document\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-search-document\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-curie-query-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-babbage-doc-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-search-document\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-curie-doc-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-search-query\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-babbage-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-davinci-doc-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-babbage-query-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-similarity\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-davinci-001\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-002\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-similarity\",\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of all available models of open ai\n",
    "openai.Engine.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8c712060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage\n",
      "davinci\n",
      "text-davinci-edit-001\n",
      "gpt-3.5-turbo-0301\n",
      "babbage-code-search-code\n",
      "text-similarity-babbage-001\n",
      "gpt-3.5-turbo\n",
      "code-davinci-edit-001\n",
      "text-davinci-001\n",
      "text-davinci-003\n",
      "ada\n",
      "babbage-code-search-text\n",
      "babbage-similarity\n",
      "code-search-babbage-text-001\n",
      "text-curie-001\n",
      "whisper-1\n",
      "code-search-babbage-code-001\n",
      "text-ada-001\n",
      "text-embedding-ada-002\n",
      "text-similarity-ada-001\n",
      "curie-instruct-beta\n",
      "ada-code-search-code\n",
      "ada-similarity\n",
      "code-search-ada-text-001\n",
      "text-search-ada-query-001\n",
      "davinci-search-document\n",
      "ada-code-search-text\n",
      "text-search-ada-doc-001\n",
      "davinci-instruct-beta\n",
      "text-similarity-curie-001\n",
      "code-search-ada-code-001\n",
      "ada-search-query\n",
      "text-search-davinci-query-001\n",
      "curie-search-query\n",
      "davinci-search-query\n",
      "babbage-search-document\n",
      "ada-search-document\n",
      "text-search-curie-query-001\n",
      "text-search-babbage-doc-001\n",
      "curie-search-document\n",
      "text-search-curie-doc-001\n",
      "babbage-search-query\n",
      "text-babbage-001\n",
      "text-search-davinci-doc-001\n",
      "text-search-babbage-query-001\n",
      "curie-similarity\n",
      "curie\n",
      "text-similarity-davinci-001\n",
      "text-davinci-002\n",
      "davinci-similarity\n",
      "cushman:2020-05-03\n",
      "ada:2020-05-03\n",
      "babbage:2020-05-03\n",
      "curie:2020-05-03\n",
      "davinci:2020-05-03\n",
      "if-davinci-v2\n",
      "if-curie-v2\n",
      "if-davinci:3.0.0\n",
      "davinci-if:3.0.0\n",
      "davinci-instruct-beta:2.0.0\n",
      "text-ada:001\n",
      "text-davinci:001\n",
      "text-curie:001\n",
      "text-babbage:001\n"
     ]
    }
   ],
   "source": [
    "# List the available models\n",
    "models = openai.Model.list()\n",
    "for model in models['data']:\n",
    "    print(model['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fad59488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"created\": 1649358449,\n",
      "      \"id\": \"babbage\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669085501,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-49FUp5v084tBB49tC4z8LPH5\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"babbage\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649359874,\n",
      "      \"id\": \"davinci\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066355,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-U6ZwlyAd0LyMk4rcMdz33Yc3\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649809179,\n",
      "      \"id\": \"text-davinci-edit-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1679934178,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-otmQSS0hmabtVGHI9QB3bct3\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-davinci-edit-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1677649963,\n",
      "      \"id\": \"gpt-3.5-turbo-0301\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1681938856,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-yDCC5ePuUJKmUe3ld1q1pKvA\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"gpt-3.5-turbo-0301\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"babbage-code-search-code\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669085863,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-4qRnA3Hj8HIJbgo0cGbcmErn\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"babbage-code-search-code\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"text-similarity-babbage-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669081947,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-48kcCHhfzvnfY84OtJf5m8Cz\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-similarity-babbage-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1677610602,\n",
      "      \"id\": \"gpt-3.5-turbo\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1681938917,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-nH8mIzR6ChcOTZNawZgHl7yK\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"gpt-3.5-turbo\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649880484,\n",
      "      \"id\": \"code-davinci-edit-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1679934178,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-Foe5Y4TvaKveYxt74oKMw8IB\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"code-davinci-edit-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649364042,\n",
      "      \"id\": \"text-davinci-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066355,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-MVM5NfoRjXkDve3uQW3YZDDt\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-davinci-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1669599635,\n",
      "      \"id\": \"text-davinci-003\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-internal\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1682112392,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-oyykgcqEhcKfSCh5Ca9BETGH\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-davinci-003\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649357491,\n",
      "      \"id\": \"ada\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1675997661,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-u0nKN4ub7EVQudgMuvCuvDjc\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"ada\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"babbage-code-search-text\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669085863,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-Lftf8H4ZPDxNxVs0hHPJBUoe\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"babbage-code-search-text\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"babbage-similarity\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669081947,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-mS20lnPqhebTaFPrcCufyg7m\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"babbage-similarity\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"code-search-babbage-text-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669085863,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-EC5ASz4NLChtEV1Cwkmrwm57\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"code-search-babbage-text-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649364043,\n",
      "      \"id\": \"text-curie-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1679310997,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-8InhPV3CZfN3F5QHKoJd4zRD\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-curie-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1677532384,\n",
      "      \"id\": \"whisper-1\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-internal\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1680896832,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-JdDYm8KjLd5xnGMGVlwX1UAp\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"whisper-1\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"code-search-babbage-code-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669085864,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-64LWHdlANgak2rHzc3K5Stt0\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"code-search-babbage-code-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649364042,\n",
      "      \"id\": \"text-ada-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669088497,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-KN5dRBCEW4az6gwcGXkRkMwK\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-ada-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1671217299,\n",
      "      \"id\": \"text-embedding-ada-002\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-internal\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1678892857,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-Dbv2FOgMdlDjO8py8vEjD5Mi\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-embedding-ada-002\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"text-similarity-ada-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669092759,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-DdCqkqmORpqxqdg4TkFRAgmw\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-similarity-ada-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649364042,\n",
      "      \"id\": \"curie-instruct-beta\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1680267269,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-bsg59MlOi88CMf1MjnIKrT5a\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"curie-instruct-beta\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"ada-code-search-code\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669087421,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-wa8tg4Pi9QQNaWdjMTM8dkkx\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"ada-code-search-code\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"ada-similarity\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669092759,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-LtSIwCEReeDcvGTmM13gv6Fg\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"ada-similarity\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"code-search-ada-text-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669087421,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-JBssaJSmbgvJfTkX71y71k2J\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"code-search-ada-text-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"text-search-ada-query-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669092640,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-1YiiBMYC8it0mpQCBK7t8uSP\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-ada-query-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"davinci-search-document\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066355,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-M43LVJQRGxz6ode34ctLrCaG\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci-search-document\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172510,\n",
      "      \"id\": \"ada-code-search-text\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669087421,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-kFc17wOI4d1FjZEaCqnk4Frg\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"ada-code-search-text\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"text-search-ada-doc-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669092640,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-kbHvYouDlkD78ehcmMOGdKpK\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-ada-doc-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649364042,\n",
      "      \"id\": \"davinci-instruct-beta\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066356,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-k9kuMYlfd9nvFiJV2ug0NWws\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci-instruct-beta\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"text-similarity-curie-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669079883,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-6dgTTyXrZE7d53Licw4hYkvd\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-similarity-curie-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"code-search-ada-code-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669087421,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-8soch45iiGvux5Fg1ORjdC4s\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"code-search-ada-code-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"ada-search-query\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669092640,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-b753xmIzAUkluQ1L20eDZLtQ\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"ada-search-query\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"text-search-davinci-query-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066353,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-9McKbsEYSaDshU9M3bp6ejUb\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-davinci-query-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"curie-search-query\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1677273417,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-sIbfSwzVpVBtymQgOQSLBpxe\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"curie-search-query\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"davinci-search-query\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066353,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-lYkiTZMmJMWm8jvkPx2duyHE\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci-search-query\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172510,\n",
      "      \"id\": \"babbage-search-document\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669084981,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-5qFV9kxCRGKIXpBEP75chmp7\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"babbage-search-document\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172507,\n",
      "      \"id\": \"ada-search-document\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669092640,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-8qUMuMAbo4EwedbGamV7e9hq\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"ada-search-document\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"text-search-curie-query-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1677273417,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-Iion0NCpsXPNtIkQ0owQLi7V\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-curie-query-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"text-search-babbage-doc-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669084981,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-ao2r26P2Th7nhRFleHwy2gn5\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-babbage-doc-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172508,\n",
      "      \"id\": \"curie-search-document\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1677273417,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-LDsN5wW8eKVuh1OsyciHntE9\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"curie-search-document\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"text-search-curie-doc-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1677273417,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-taUGRSku7bQLa24SNIwYPEsi\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-curie-doc-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"babbage-search-query\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669084981,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-wSs1hMXDKsrcErlbN8HmzlLE\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"babbage-search-query\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649364043,\n",
      "      \"id\": \"text-babbage-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1675105935,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-a3Ph5FIBbJxsoA4wvx7VYC7R\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-babbage-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"text-search-davinci-doc-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066353,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-qhSf1j2MJMujcu3t7cHnF1DN\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-davinci-doc-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"text-search-babbage-query-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669084981,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-Kg70kkFxD93QQqsVe4Zw8vjc\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-search-babbage-query-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172510,\n",
      "      \"id\": \"curie-similarity\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1675106290,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-zhWKExSloaQiJgzjVHFmh2wR\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"curie-similarity\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649359874,\n",
      "      \"id\": \"curie\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1675106503,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-oPaljeveTjEIDbhDjzFiyf4V\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"curie\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172505,\n",
      "      \"id\": \"text-similarity-davinci-001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066356,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-OvmcfYoq5V9SF9xTYw1Oz6Ue\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-similarity-davinci-001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1649880484,\n",
      "      \"id\": \"text-davinci-002\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1679355287,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-l4EU6QlN1HcS0so0jU16kyg8\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-davinci-002\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1651172509,\n",
      "      \"id\": \"davinci-similarity\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai-dev\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1669066353,\n",
      "          \"group\": null,\n",
      "          \"id\": \"modelperm-lYYgng3LM0Y97HvB5CDc8no2\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci-similarity\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1590625110,\n",
      "      \"id\": \"cushman:2020-05-03\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": true,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1590625111,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-FAup8P1KqclNlTsunLDRiesT\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"cushman:2020-05-03\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1607631625,\n",
      "      \"id\": \"ada:2020-05-03\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1607631626,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-9TYofAqUs54vytKYL0IX91rX\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"ada:2020-05-03\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1607632611,\n",
      "      \"id\": \"babbage:2020-05-03\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1607632613,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-jaLAcmyyNuaVmalCE1BGTGwf\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"babbage:2020-05-03\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1607632725,\n",
      "      \"id\": \"curie:2020-05-03\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1607632727,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-bt6R8PWbB2SwK5evFo0ZxSs4\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"curie:2020-05-03\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1607640163,\n",
      "      \"id\": \"davinci:2020-05-03\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1607640164,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-99cbfQTYDVeLkTYndX3UMpSr\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci:2020-05-03\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1610745990,\n",
      "      \"id\": \"if-davinci-v2\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1610746036,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-58q0TdK2K4kMgL3MoHvGWMlH\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"if-davinci-v2\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1610745968,\n",
      "      \"id\": \"if-curie-v2\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1610746043,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-fwAseHVq6NGe6Ple6tKfzRSK\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"if-curie-v2\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1629420755,\n",
      "      \"id\": \"if-davinci:3.0.0\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": true,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1629421809,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-T53lssiyMWwiuJwhyO9ic53z\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"if-davinci:3.0.0\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1629498070,\n",
      "      \"id\": \"davinci-if:3.0.0\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": true,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1629498084,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-s6ZIAVMwlZwrLGGClTXqSK3Q\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci-if:3.0.0\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1629501914,\n",
      "      \"id\": \"davinci-instruct-beta:2.0.0\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": true,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1629501939,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-c70U4TBfiOD839xptP5pJzyc\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"davinci-instruct-beta:2.0.0\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1641949608,\n",
      "      \"id\": \"text-ada:001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1641949610,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-d2PSnwFG1Yn9of6PvrrhkBcU\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-ada:001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1641943966,\n",
      "      \"id\": \"text-davinci:001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1641944340,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-Fj1O3zkKXOQy6AkcfQXRKcWA\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-davinci:001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1641955047,\n",
      "      \"id\": \"text-curie:001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"system\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1641955123,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-BI9TAT6SCj43JRsUb9CYadsz\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-curie:001\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 1642018370,\n",
      "      \"id\": \"text-babbage:001\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"created\": 1642018480,\n",
      "          \"group\": null,\n",
      "          \"id\": \"snapperm-7oP3WFr9x7qf5xb3eZrVABAH\",\n",
      "          \"is_blocking\": false,\n",
      "          \"object\": \"model_permission\",\n",
      "          \"organization\": \"*\"\n",
      "        }\n",
      "      ],\n",
      "      \"root\": \"text-babbage:001\"\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fa064ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response5 = openai.Edit.create(\n",
    "  model=\"code-davinci-edit-001\",\n",
    "  input=f\"give me python code to create the file structure and empty files in each folder for this project:{project}\",\n",
    "  instruction=\"the code should be in python\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "910c1896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject edit at 0x107bc4b30> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"text\": \"write me code to print an array of integers from 1 to 100 in python\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1682322819,\n",
       "  \"object\": \"edit\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 39,\n",
       "    \"prompt_tokens\": 30,\n",
       "    \"total_tokens\": 69\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Edit.create(\n",
    "  model=\"code-davinci-edit-001\",\n",
    "  input=f\"write me code to print an array of integers from 1 to 100\",\n",
    "  instruction=\"output should be in python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "052cc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me python code to create the file structure and empty files in each folder for this project:5. Weather data dashboard: Using FastAPI to retrieve weather data from various sources, such as APIs from weather services, and use Streamlit to visualize the data in a dashboard. Store the data in an AWS database such as Amazon RDS and use AWS Lambda to trigger notifications on changes in weather patterns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response5[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8ae665c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "response_string = '[1, 2, 3, 4, 5]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8b5c3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = ast.literal_eval(response_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ff3c9b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(response_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
